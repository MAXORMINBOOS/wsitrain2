import argparse
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import StepLR
from models import *
from wsi_dataset import WsiDataset
from utils.utils import *
from topk.svm import SmoothTop1SVM
import pandas as pd
from tqdm import tqdm
from PIL import Image
import cv2
from datetime import datetime
import warnings
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.optim.lr_scheduler import LambdaLR
warnings.filterwarnings("ignore")

# ------------------ æ–°å¢å¯¼å…¥ ------------------
from transformers import AutoModel, AutoImageProcessor
from create_label import create_fold
# ---------------------------------------------------

torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
torch.set_float32_matmul_precision('high')

project_root = os.path.dirname(os.path.abspath(__file__))

def parse_args():
    parser = argparse.ArgumentParser(description="æ¨¡å‹è®­ç»ƒè„šæœ¬")

    parser.add_argument('--n_classes', type=int, default=2)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--batch_size', type=int, default=1)
    parser.add_argument('--log_dir', type=str, default='logs')
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--max_epochs', type=int, default=100)
    parser.add_argument('--patience', type=int, default=20)
    parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')
    parser.add_argument('--model_name', type=str, default='CLAM_MB', help="æ¨¡å‹åç§°ï¼Œå¦‚ TransMILã€CLAM ç­‰")
    parser.add_argument('--instance_eval', type=bool, default=False)
    parser.add_argument('--in_dim', type=int, default=512)
    parser.add_argument('--hidden_dim', type=int, default=512)
    parser.add_argument('--inst_loss', type=str, default='cr')
    parser.add_argument('--n_fold', type=int, default=0)
    parser.add_argument('--data_dir', type=str, default='D:/postgraduate/WSIDATA/patch_output/only_pre_operation', help="åŸå§‹æ‚£è€…æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå«patchå›¾åƒï¼‰")
    parser.add_argument('--label_csv', type=str, default='D:/postgraduate/WSIDATA/patch_output/label.csv', help="æ ‡ç­¾æ–‡ä»¶è·¯å¾„")
    parser.add_argument('--feature_dir', type=str, default=os.path.join(project_root, 'features_resnet/pt'), help="æå–åçš„ç‰¹å¾ä¿å­˜è·¯å¾„")
    parser.add_argument('--csv_dir', type=str, default=os.path.join(project_root, 'csv'), help="fold csvä¿å­˜è·¯å¾„")
    parser.add_argument('--encoder', type=str, default='uni', help="ç‰¹å¾æå–æ¨¡å‹ UNI2-h / UNI / CONCH")
    # parser.add_argument('--n_fold', type=str, default='0', help="n_fold")
    return parser.parse_args()


# ç»„ç»‡åŒºåŸŸæå–ï¼ˆç®€å•Otsuç¤ºä¾‹ï¼‰
def tissue_mask(img):
    gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    mask = cv2.bitwise_not(mask)
    masked = cv2.bitwise_and(np.array(img), np.array(img), mask=mask)
    return Image.fromarray(masked)


# ------------------ æ–°å¢ç‰¹å¾æå–å‡½æ•° ------------------
@torch.no_grad()
def extract_features_from_patches(model_name, data_root, out_root, batch_size=64):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    os.makedirs(out_root, exist_ok=True)
    if model_name.lower() == 'uni':
        print("ğŸ§  æ­£åœ¨åŠ è½½è‡ªå®šä¹‰ UNI ç¼–ç å™¨...")
        from UNI import model
        model = model.to(device)
        model.eval()
        # å®šä¹‰é¢„å¤„ç†ï¼ˆå¯¹åº” img_size = 224ï¼‰
        processor = transforms.Compose([
            # transforms.Lambda(lambda img: tissue_mask(img)),  # å»é™¤èƒŒæ™¯
            # transforms.Resize((224, 224)),
            # transforms.RandomHorizontalFlip(),

            # transforms.RandomVerticalFlip(),
            # transforms.RandomRotation(90),
            # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])
    else:
        processor = AutoImageProcessor.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device)
        model.eval()

    patients = os.listdir(data_root)
    for patient_id in tqdm(patients, desc="Extracting features"):
        patient_dir = os.path.join(data_root, patient_id)
        if not os.path.isdir(patient_dir):
            continue
        img_files = [f for f in os.listdir(patient_dir) if f.lower().endswith('.png')]
        feats = []
        batch = []
        for img_name in img_files:
            img_path = os.path.join(patient_dir, img_name)
            image = Image.open(img_path).convert("RGB")
            batch.append(image)

            if len(batch) == batch_size:
                inputs = torch.stack([processor(img) for img in batch]).to(device)
                with torch.no_grad():
                    if hasattr(model, "forward_features"):
                        outputs = model.forward_features(inputs)
                    else:
                        outputs = model(inputs)

                # è‡ªåŠ¨åˆ¤æ–­ç»´åº¦
                if outputs.ndim == 3:
                    feat = outputs[:, 0, :].cpu()
                elif outputs.ndim == 2:
                    feat = outputs.cpu()
                else:
                    raise ValueError(f"Unexpected output shape: {outputs.shape}")

                feats.append(feat)
                batch = []

        # å¤„ç†æœ€åæ®‹ä½™ batch
        if batch:
            inputs = torch.stack([processor(img) for img in batch]).to(device)
            with torch.no_grad():
                if hasattr(model, "forward_features"):
                    outputs = model.forward_features(inputs)
                else:
                    outputs = model(inputs)

            if outputs.ndim == 3:
                feat = outputs[:, 0, :].cpu()
            elif outputs.ndim == 2:
                feat = outputs.cpu()
            else:
                raise ValueError(f"Unexpected output shape: {outputs.shape}")

            feats.append(feat)

        # ä¿å­˜ç‰¹å¾
        features = torch.cat(feats, dim=0)
        torch.save({'features': features, 'feat_dim': features.shape[1]},
                   os.path.join(out_root, f"{patient_id}.pt"))

# ---------------------------------------------------


def main():
    args = parse_args()
    set_random_seed(args.seed)

    # ---------- Step 1: ç‰¹å¾æå– ----------
    if not os.path.exists(args.feature_dir) or len(os.listdir(args.feature_dir)) == 0:
        print(f"æœªæ£€æµ‹åˆ°ç‰¹å¾æ–‡ä»¶ï¼Œå¼€å§‹ä½¿ç”¨ {args.encoder} æå–ç‰¹å¾...")
        extract_features_from_patches(args.encoder, args.data_dir, args.feature_dir)
        print("ç‰¹å¾æå–å®Œæˆï¼")
    else:
        print(f"æ£€æµ‹åˆ°å·²æœ‰ç‰¹å¾æ–‡ä»¶ï¼š{args.feature_dir}ï¼Œè·³è¿‡æå–ã€‚")

    # ---------- Step 2: ç”ŸæˆCSVåˆ’åˆ† ----------
    if not os.path.exists(args.csv_dir) or len(os.listdir(args.csv_dir)) == 0:
        print("æœªæ£€æµ‹åˆ°foldåˆ’åˆ†CSVï¼Œè‡ªåŠ¨åˆ›å»ºä¸­...")
        df = pd.read_csv(args.label_csv,encoding='gbk')
        label_dict = dict(zip(df['patient_id'], df['label']))
        create_fold(label_dict, nfold=5, val_ratio=0.2, save_dir=args.csv_dir)
        print("CSVç”Ÿæˆå®Œæˆï¼")
    else:
        print(f"æ£€æµ‹åˆ°å·²æœ‰CSVæ–‡ä»¶ï¼š{args.csv_dir}")

    # ---------- Step 3: åŸå§‹è®­ç»ƒé€»è¾‘ï¼ˆç‰¹å¾èšåˆæ¨¡å—ï¼‰ ----------
    log_dir = f"{args.log_dir}/{args.model_name}/fold{args.n_fold}/"
    csv_dir = f"{args.csv_dir}/fold{args.n_fold}.csv"

    if 'CLAM' in args.model_name and args.inst_loss == 'svm':
        criterion = SmoothTop1SVM(n_classes=2).to(args.device)
    else:
        criterion = nn.CrossEntropyLoss().to(args.device)

    # ---------- Step X: è‡ªåŠ¨æ£€æµ‹ç‰¹å¾ç»´åº¦ ----------

    # # æ‰¾åˆ°ä¸€ä¸ªç‰¹å¾æ–‡ä»¶
    # sample_feats = None
    # for f in os.listdir(args.feature_dir):
    #     if f.endswith('.pt'):
    #         sample_feats = os.path.join(args.feature_dir, f)
    #         break
    #
    # if sample_feats is not None:
    #     feat_file = torch.load(sample_feats, map_location='cpu')
    #     if 'feat_dim' in feat_file:
    #         detected_dim = feat_file['feat_dim']
    #     else:
    #         detected_dim = feat_file['features'].shape[1]
    #     print(f"æ£€æµ‹åˆ°ç‰¹å¾ç»´åº¦: {detected_dim}")
    #     args.in_dim = detected_dim
    # else:
    #     print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• .pt ç‰¹å¾æ–‡ä»¶ï¼Œæ— æ³•æ£€æµ‹è¾“å…¥ç»´åº¦ã€‚è¯·æ£€æŸ¥ç‰¹å¾ç›®å½•ã€‚")

    sample_feats = None
    for f in os.listdir(args.feature_dir):
        if f.endswith('.pt'):
            sample_feats = os.path.join(args.feature_dir, f)
            break

    if sample_feats is not None:
        feat_file = torch.load(sample_feats, map_location='cpu')

        # ğŸ©¹ ä¿®å¤ï¼šå…ˆåˆ¤æ–­ç±»å‹
        if isinstance(feat_file, dict):
            if 'feat_dim' in feat_file:
                detected_dim = feat_file['feat_dim']
            elif 'features' in feat_file:
                detected_dim = feat_file['features'].shape[1]
            else:
                raise ValueError(f"æœªçŸ¥çš„ç‰¹å¾æ–‡ä»¶ç»“æ„: {sample_feats}")
        elif isinstance(feat_file, torch.Tensor):
            detected_dim = feat_file.shape[1]
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„ç‰¹å¾æ–‡ä»¶ç±»å‹: {type(feat_file)}")

        print(f"âœ… æ£€æµ‹åˆ°ç‰¹å¾ç»´åº¦: {detected_dim}")
        args.in_dim = detected_dim
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• .pt ç‰¹å¾æ–‡ä»¶ï¼Œæ— æ³•æ£€æµ‹è¾“å…¥ç»´åº¦ã€‚è¯·æ£€æŸ¥ç‰¹å¾ç›®å½•ã€‚")

    model = create_model('models', args.model_name, args.n_classes, args.in_dim, args.hidden_dim, instance_eval=args.instance_eval)
    model.apply(init_weights_he)
    model.to(device=args.device)

    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)

    # å®šä¹‰å­¦ä¹ ç‡è¡°å‡
    scheduler = ReduceLROnPlateau(
        optimizer,
        mode='min',  # æŒ‡æ ‡è¶Šå°è¶Šå¥½ï¼ˆlossï¼‰
        factor=0.5,  # å­¦ä¹ ç‡ç¼©æ”¾ç³»æ•°ï¼ˆlr_new = lr_old * factorï¼‰
        patience=5,  # è‹¥éªŒè¯é›†æ€§èƒ½5ä¸ªepochæ— æå‡ï¼Œåˆ™é™ä½å­¦ä¹ ç‡
        threshold=1e-4,  # æå‡å°äºè¯¥é˜ˆå€¼è§†ä¸ºâ€œæ— æå‡â€
        cooldown=2,  # é™lråç­‰å¾…1ä¸ªepochå†ç»§ç»­ç›‘æµ‹
        min_lr=1e-7,  # æœ€å°å­¦ä¹ ç‡ä¸‹é™
        verbose=True  # æ‰“å°å­¦ä¹ ç‡è°ƒæ•´æ—¥å¿—
    )

    train_dataset = WsiDataset(data_dir=args.feature_dir, csv_path=csv_dir, state='train')
    val_dataset = WsiDataset(data_dir=args.feature_dir, csv_path=csv_dir, state='val')

    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=8)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=8)

    log_dir = os.path.join(args.log_dir, f"{args.model_name}/fold_{args.n_fold}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")\









    if args.model_name == 'CLAM_MB' and args.instance_eval:
        model=train_model_clam(model, args.device, train_loader, val_loader, criterion, optimizer, scheduler,
                         num_epochs=args.max_epochs, patience=args.patience, log_dir=log_dir)
    else:
        model=train_model(model, args.device, train_loader, val_loader, criterion, optimizer, scheduler,
                    num_epochs=args.max_epochs, patience=args.patience, log_dir=log_dir)


if __name__ == '__main__':
    main()
